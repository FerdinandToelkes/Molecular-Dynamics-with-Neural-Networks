import os
import argparse
import numpy as np
import pandas as pd

from schnetpack.data import ASEAtomsData
from ase import Atoms
from ase.data import atomic_numbers as ase_atomic_numbers

from md_with_schnet.units import convert_distances, convert_energies, convert_forces, convert_velocities, get_ase_unit_format
from md_with_schnet.utils import set_data_prefix
from md_with_schnet.setup_logger import setup_logger

from exited_md.preprocessing.utils import prepare_last_exited_cycles


logger = setup_logger(logging_level_str="debug")


# Example command to run the script from within code directory:
"""
python -m exited_md.preprocessing.prepare_tddft_data  --num_atoms 48 --position_unit bohr --energy_unit hartree --time_unit aut
"""

# Note: 
# - The last mdlog file contains one extra cycle (marked by $current) 
# -> warning will be logged when extracting the positions and velocities
# - just take the first n cycles, that are also in the energies.csv file (which does not contain this $current cycle)
# - Note that we only have the velocities for the active state

def parse_args() -> dict:
    """ 
    Parse command-line arguments. 
    Returns:
        dict: Dictionary containing command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Prepare TDDFT data for usage in SchNetPack")
    parser.add_argument("--target_dir", type=str, default="PREPARE_12", help="Directory containing the trajectory data generated by Turbomole (default: PREPARE_12)")
    parser.add_argument("--computed_cycles", type=int, default=1461, help="Number of cycles for which the gradients were computed (default: 1461)")
    parser.add_argument('--num_atoms', type=int, required=True, help='Number of atoms in the simulation. Can be found in the "control" file under "natoms".')
    parser.add_argument('--position_unit', type=str, default='angstrom', choices=['angstrom', 'bohr'], help='Target unit for positions to transform from atomic units to (default: angstrom)')
    parser.add_argument('--energy_unit', type=str, default='kcal/mol', choices=['kcal/mol', 'hartree', "ev"], help='Target unit for energies to transform from atomic units to (default: kcal/mol)')
    parser.add_argument('--time_unit', type=str, default='fs', choices=['fs', 'aut'], help='Target unit for time to transform from atomic units to (default: fs)')
    return vars(parser.parse_args())

def get_atomic_numbers_from_xyz(path: str, number_of_atoms: int, extra_lines: int) -> list:
    """
    Extract atomic symbols from a .xyz file and convert them to atomic numbers.
    Args:
        path (str): Path to the .xyz file.
        number_of_atoms (int): Number of atoms in the system.
        extra_lines (int): Number of extra lines in each coordinates block, e.g., header lines.
    Returns:
        list: List of atomic numbers.
    """
    with open(path, 'r') as file:
        lines = file.readlines()
        atom_lines = lines[extra_lines:extra_lines + number_of_atoms]  # Skip the first n lines
        symbols = [line.split()[0] for line in atom_lines]
    logger.debug(f'symbols: {symbols}')

    # Convert symbols to atomic numbers
    atomic_numbers = [ase_atomic_numbers[symbol] for symbol in symbols]
    logger.debug(f'atomic_numbers: {atomic_numbers}')

    if len(atomic_numbers) != number_of_atoms:
        raise ValueError(f"Number of atomic_numbers extracted ({len(atomic_numbers)}) does not match the expected number of atoms ({number_of_atoms}).")
    
    return atomic_numbers

def get_all_energies_from_csv(path: str) -> tuple:
    """
    Extract all (potential) energies for the S0 and S1 state from a .csv file and return them as a NumPy array.
    Args:
        path (str): Path to the .csv file.
    Returns:
        tuple: Tuple containing all energies and the number of samples.
    """
    df = pd.read_csv(path, comment='#')
    s0_energies = df['S0'].values
    s1_energies = df['S1'].values
    number_of_samples = df.shape[0]
    logger.debug(f's0_energies.shape: {s0_energies.shape}')
    logger.debug(f's1_energies.shape: {s1_energies.shape}') 
    logger.debug(f'number_of_samples: {number_of_samples}')
    return s0_energies, s1_energies, number_of_samples

def get_trajectory_from_txt_and_reshape(path: str, number_of_samples: int, 
                                        num_atoms: int, usecols: tuple[int] = (1, 2, 3)) -> np.ndarray:
    """
    Load trajectory data from a .txt file and reshape it to the desired format.
    Args:
        path (str): Path to the .txt file containing trajectory data.
        number_of_samples (int): Number of samples to align with.
        num_atoms (int): Number of atoms in the system.
        usecols (tuple[int]): Columns to use from the .txt file. Default is (1, 2, 3) which skips the element symbols.
    Returns:
        np.ndarray: Reshaped trajectory data with shape (Nframes, Natoms, 3).
    """
    traj = np.loadtxt(path, usecols=usecols, comments=["#", "t="]) 
    traj = traj.reshape(-1, num_atoms, 3)  # Shape: (Nframes, Natoms, 3)
    traj = align_shapes(number_of_samples, traj)
    return traj


def align_shapes(number_of_samples: int, traj: np.ndarray) -> np.ndarray:
    """
    Align the shape of the trajectory data with the number of samples given by the energy trajectory.
    Args:
        number_of_samples (int): Number of samples to align with.
        traj (np.ndarray): Trajectory data to align.
    Returns:
        np.ndarray: Aligned trajectory data.
    """
    if traj.shape[0] != number_of_samples:
        logger.warning(f'traj.shape[0] != number_of_samples: {traj.shape[0]} != {number_of_samples}')
        logger.warning("Just using the first number_of_samples samples from grads_traj")
        traj = traj[:number_of_samples]
    return traj

def convert_trajectory_to_ase_and_append(
        property_list: list, atoms_list: list, coords_traj: np.ndarray, s0_energy_traj: np.ndarray, s1_energy_traj: np.ndarray,
        s0_forces_traj: np.ndarray, s1_forces_traj: np.ndarray, nacs_traj: np.ndarray, velocities_traj: np.ndarray, atomic_numbers: list
    ) -> tuple:
    """
    Convert current trajectory data to ASE Atoms objects and properties and append them to the lists.
    Args:
        coords_traj (np.ndarray): Coordinates of the trajectory.
        s0_energy_traj (np.ndarray): Energies of the ground state trajectory.
        s1_energy_traj (np.ndarray): Energies of the excited state trajectory.
        s0_forces_traj (np.ndarray): Forces of the ground state trajectory.
        s1_forces_traj (np.ndarray): Forces of the excited state trajectory.
        nacs_traj (np.ndarray): Non-adiabatic couplings of the trajectory.
        velocities_traj (np.ndarray): Velocities of the trajectory.
        atomic_numbers (list): List of atomic numbers.
    Returns:
        tuple: Tuple containing a list of ASE Atoms objects and a list of properties.
    """
    logger.debug("Converting trajectory data to ASE Atoms objects and properties")

    for positions, s0_energies, s1_energies, s0_forces, s1_forces, nacs, velocities in zip(coords_traj, s0_energy_traj, s1_energy_traj, s0_forces_traj, s1_forces_traj, nacs_traj, velocities_traj):
        ats = Atoms(positions=positions, numbers=atomic_numbers)
        # convert energies to array if it is not already
        if not isinstance(s0_energies, np.ndarray):
            s0_energies = np.array([s0_energies]) # compare with shape of data within the SchNetPack tutorial
        if not isinstance(s1_energies, np.ndarray):
            s1_energies = np.array([s1_energies])

        properties = {'s0_energy': s0_energies, 's1_energy': s1_energies, 's0_forces': s0_forces, 
                      's1_forces': s1_forces, 'nacs': nacs, 'velocities': velocities}
        property_list.append(properties)
        atoms_list.append(ats)
    logger.debug(f'Properties: {property_list[0]}')
    return atoms_list, property_list

def get_overview_of_dataset(new_dataset: ASEAtomsData):
    """
    Get an overview of the dataset.
    Args:
        new_dataset (ASEAtomsData): The dataset to analyze.
    """
    logger.debug(f'Number of reference calculations: {len(new_dataset)}')
    print('Available properties:')

    for p in new_dataset.available_properties:
        print('-', p)
    print()

    print(f"new_dataset: {new_dataset}")
    example = new_dataset[0]
    print('Properties of molecule with id 0:')

    for k, v in example.items():
        print('-', k, ':', v.shape)



def main(target_dir: str, computed_cycles: int, num_atoms: int, position_unit: str, energy_unit: str, time_unit: str):
    """
    Main function to prepare XTB data in units of Angstrom and kcal/mol for usage in SchNetPack.
    Args:
        target_dir (str): Directory containing the GEO folders containing exited state trajectories generated by Turbomole.
        computed_cycles (int): Number of cycles for which the gradients were computed.
        num_atoms (int): Number of atoms in the simulation. Can be found in the "control" file under "natoms".
        position_unit (str): Target unit for positions to transform from atomic units to (default: angstrom).
        energy_unit (str): Target unit for energies to transform from atomic units to (default: kcal/mol).
        time_unit (str): Target unit for time to transform from atomic units to (default: fs).
    """
    # setup paths to the necessary files
    data_path = os.path.join(set_data_prefix(), target_dir)

    # get all viable GEO folders
    # get all valid trajectories and the number of their last exited cycles
    geo_dirs_with_last_exited_cycles = prepare_last_exited_cycles(data_path, computed_cycles)
    print(f"Found {len(geo_dirs_with_last_exited_cycles)} valid GEO folders in {data_path}")
    print(f"Last exited cycles: {geo_dirs_with_last_exited_cycles}")

    # setup lists to store data in ase format
    atoms_list = []
    property_list = []
    for geo_dir, _last_exited_cycle in geo_dirs_with_last_exited_cycles.items():
        logger.debug(f"Processing GEO folder: {geo_dir}")
        # setup paths to the necessary files
        data_prefix = os.path.join(data_path, geo_dir, "test")
        logger.debug(f"data_prefix: {data_prefix}")

        traj_path = os.path.join(data_prefix, 'positions.txt')
        energy_path = os.path.join(data_prefix, 'energies.csv')
        s0_grads_path = os.path.join(data_prefix, 's0_gradients.txt')
        s1_grads_path = os.path.join(data_prefix, 's1_gradients.txt')
        nacs_path = os.path.join(data_prefix, 'nacs.txt')
        vels_path = os.path.join(data_prefix, 'velocities.txt')

        # check if all necessary files exist
        if not os.path.exists(traj_path) or not os.path.exists(energy_path) or not os.path.exists(s0_grads_path) or not os.path.exists(s1_grads_path) or not os.path.exists(nacs_path) or not os.path.exists(vels_path):
            raise FileNotFoundError(f"One or more files do not exist in the specified directory: {data_prefix}\n"
                                    "Try running the extract scripts for the different properties.")
        
        logger.debug("Extracting data from prepared .csv and .txt files")
        db_name = f"md_trajectory_{position_unit}_{energy_unit.replace('/', '_per_')}_{time_unit}.db"
        target_path = os.path.join(data_prefix, db_name)

        s0_energy_traj, s1_energy_traj, number_of_samples  = get_all_energies_from_csv(energy_path)
        coords_traj = get_trajectory_from_txt_and_reshape(traj_path, number_of_samples, num_atoms, usecols=(1, 2, 3))
        s0_grads_traj = get_trajectory_from_txt_and_reshape(s0_grads_path, number_of_samples, num_atoms, usecols=(0, 1, 2))
        s1_grads_traj = get_trajectory_from_txt_and_reshape(s1_grads_path, number_of_samples, num_atoms, usecols=(0, 1, 2))
        s0_forces_traj = -s0_grads_traj  # Convert gradients to forces
        s1_forces_traj = -s1_grads_traj  # Convert gradients to forces
        nacs_traj = get_trajectory_from_txt_and_reshape(nacs_path, number_of_samples, num_atoms, usecols=(0, 1, 2))
        velocities_traj = get_trajectory_from_txt_and_reshape(vels_path, number_of_samples, num_atoms, usecols=(1, 2, 3))
        atomic_numbers = get_atomic_numbers_from_xyz(traj_path, num_atoms, extra_lines=3)

        # covert from atomic units to desired units
        force_unit = f"{energy_unit}/{position_unit}"  # e.g., kcal/mol/Angstrom
        velocity_unit = f"{position_unit}/{time_unit}"  # e.g., Angstrom/fs
        logger.info(f"Converting units from atomic units to {position_unit}, {energy_unit} and {time_unit} (and {force_unit}, {velocity_unit})")
        coords_traj = convert_distances(coords_traj, from_units='bohr', to_units=position_unit)  
        s0_energy_traj = convert_energies(s0_energy_traj, from_units='hartree', to_units=energy_unit)
        s1_energy_traj = convert_energies(s1_energy_traj, from_units='hartree', to_units=energy_unit)
        s0_forces_traj = convert_forces(s0_forces_traj, from_units='hartree/bohr', to_units=force_unit)
        s1_forces_traj = convert_forces(s1_forces_traj, from_units='hartree/bohr', to_units=force_unit)
        velocities_traj = convert_velocities(velocities_traj, from_units='bohr/aut', to_units=velocity_unit)

        # convert trajectory data to ASE Atoms objects and properties
        atoms_list, property_list = convert_trajectory_to_ase_and_append(
            atoms_list, property_list, coords_traj, s0_energy_traj, s1_energy_traj, s0_forces_traj, 
            s1_forces_traj, nacs_traj, velocities_traj, atomic_numbers
            )
        break
    
    # Create a new dataset in the schnetpack format
    if os.path.exists(target_path):
        logger.info(f"File {target_path} already exists, loading it.")
        new_dataset = ASEAtomsData(target_path)
    else:
        logger.info(f"File {target_path} does not exist, creating it.")
        # create a new dataset
        # ase needs the distance unit in capitalized form
        ase_units = get_ase_unit_format(position_unit, energy_unit, time_unit)
        new_dataset = ASEAtomsData.create(
            target_path, 
            distance_unit=ase_units['distance'],
            property_unit_dict={
                's0_energy': ase_units['energy'],
                's1_energy': ase_units['energy'],
                's0_forces': ase_units['forces'],
                's1_forces': ase_units['forces'],
                'nacs': f"1/{ase_units['distance']}",
                'velocities': ase_units['velocities']
                },
        )
        # add systems to the dataset
        new_dataset.add_systems(property_list, atoms_list)

    # get overview of the dataset
    get_overview_of_dataset(new_dataset)

if __name__=="__main__":
    args = parse_args()
    main(**args)