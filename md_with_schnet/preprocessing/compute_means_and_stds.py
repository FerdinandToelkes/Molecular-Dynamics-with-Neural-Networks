import argparse
import os
import pytorch_lightning as pl
import schnetpack.transform as trn
import torch
from tqdm import tqdm

from md_with_schnet.setup_logger import setup_logger
from md_with_schnet.utils import set_data_prefix, get_splits_and_load_data
from md_with_schnet.preprocessing.transforms import StandardizeProperty

logger = setup_logger("debug")
# set batch size to 1, since batches are loaded weirdly (bs*num_atoms, 3) 
BATCH_SIZE = 1

# Example command to run the script from within code directory:
"""
python -m md_with_schnet.preprocessing.compute_means_and_stds --trajectory_dir MOTOR_MD_XTB/T300_1 --num_atoms=48
"""


def parse_args() -> dict:
    """ 
    Parse command-line arguments. 
    Returns:
        dict: Dictionary containing command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Script for preparing and scaling data.")
    parser.add_argument("--trajectory_dir", type=str, default="MOTOR_MD_XTB/T300_1", help="Directory containing the trajectory data generated by Turbomole (default: MOTOR_MD_XTB/T300_1)")
    parser.add_argument("--fold", type=int, default=0, help="Fold number for cross-validation (default: 0)")
    parser.add_argument('--num_atoms', type=int, required=True, help='Number of atoms in the simulation. Can be found in the "control" file under "natoms".')
    return vars(parser.parse_args())


def load_data_and_compute_stats(data_prefix: str, trajectory_dir: str, device: torch.device, fold: int, num_atoms: int) -> dict:
    """
    Load the dataset and compute the means and standard deviations of energies and forces.
    Args:
        data_prefix (str): The prefix path to the data directory.
        trajectory_dir (str): The directory containing the trajectory data.
        device (torch.device): The device to perform computations on (CPU or GPU).
        fold (int): The fold number for cross-validation.
        num_atoms (int): The number of atoms in the system.
    Returns:
        dict: A dictionary containing the mean and standard deviation of energies and forces.
    """
    train_loader = get_splits_and_load_data(
        data_prefix=data_prefix,
        trajectory_dir=trajectory_dir,
        num_workers=-1,  # Use all available CPU cores
        batch_size=BATCH_SIZE,
        transforms=[],   # No transforms for computing means and stds
        fold=fold
    ).train_dataloader()

    # Compute means and standard deviations of energies and forces
    stats = compute_means_and_stds(
        device=device,
        train_loader=train_loader,
        num_atoms=num_atoms
    )
    
    debug_stats(stats)

    return stats

def debug_stats(stats: dict):
    """
    Print the computed means and standard deviations of energies and forces for debugging.
    Args:
        stats (dict): A dictionary containing the mean and standard deviation of energies and forces.
    """
    logger.debug(f"Energy mean: {stats['energy_mean'].item()}")
    logger.debug(f"Energy std: {stats['energy_std'].item()}")
    logger.debug(f"Forces mean: {stats['forces_mean'].flatten()}")
    logger.debug(f"Forces std: {stats['forces_std'].flatten()}")
    logger.debug(f"Positions mean: {stats['positions_mean'].flatten()}")
    logger.debug(f"Positions std: {stats['positions_std'].flatten()}")

def load_transformed_data_and_compute_stats(data_prefix: str, trajectory_dir: str, device: torch.device, 
                                            num_atoms: int, stats: dict) -> dict:
    """
    Load the dataset with transforms applied and compute the means and standard deviations of energies and forces.
    Args:
        data_prefix (str): The prefix path to the data directory.
        trajectory_dir (str): The directory containing the trajectory data.
        device (torch.device): The device to perform computations on (CPU or GPU).
        num_atoms (int): The number of atoms in the system.
        stats (dict): A dictionary containing the mean and standard deviation of energies and forces.
    Returns:
        dict: A dictionary containing the mean and standard deviation of energies and forces after applying transforms.
    """
    # check if the forces mean and std are correct
    transforms = [
        StandardizeProperty(
            property_key="energy",
            property_mean=stats['energy_mean'],
            property_std=stats['energy_std']
        ),
        StandardizeProperty(
            property_key="forces",
            property_mean=stats['forces_mean'],
            property_std=stats['forces_std']
        ),
        StandardizeProperty(
            property_key="_positions",
            property_mean=stats['positions_mean'],
            property_std=stats['positions_std']
        )
    ]
    train_loader = get_splits_and_load_data(
        data_prefix=data_prefix,
        trajectory_dir=trajectory_dir,
        num_workers=-1, # Use all available CPU cores
        batch_size=BATCH_SIZE,
        transforms=transforms
    ).train_dataloader()

    # Initialize accumulators
    standardized_stats = compute_means_and_stds(
        device=device,
        train_loader=train_loader,
        num_atoms=num_atoms
    )

    debug_stats(standardized_stats)

    return standardized_stats

def compute_means_and_stds(device: torch.device, train_loader: pl.LightningDataModule, num_atoms: int) -> dict:
    """
    Compute the means and standard deviations of energies and forces from the training data.
    Args:
        device (torch.device): The device to perform computations on (CPU or GPU).
        train_loader (pl.LightningDataModule): The data module containing the training data.
        num_atoms (int): The number of atoms in the system.
    Raises:
        ValueError: If the number of atoms in the batch does not match the expected number.
        ValueError: If the force vectors do not have 3 components.
        ValueError: If the energy and forces batch sizes do not match.
    Returns:
        dict: A dictionary containing the mean and standard deviation of energies and forces.
    """
    # Initialize accumulators for means and variances
    energy_mean = torch.zeros((), dtype=torch.float64, device=device)
    energy_M2   = torch.zeros_like(energy_mean)
    forces_mean = torch.zeros((num_atoms,3), dtype=torch.float64, device=device)
    forces_M2   = torch.zeros_like(forces_mean)
    positions_mean = torch.zeros((num_atoms,3), dtype=torch.float64, device=device)
    positions_M2   = torch.zeros_like(positions_mean)
    count = 0

    # Singleâ€pass Welford (see wikipedia for details)
    for batch in tqdm(train_loader, desc="Computing stats"):
        e_batch = batch["energy"].to(dtype=torch.float64, device=device)    # (1)
        f_batch = batch["forces"].to(dtype=torch.float64, device=device)    # (N,3)
        p_batch = batch["_positions"].to(dtype=torch.float64, device=device) # (N,3)

        if f_batch.shape[0] != num_atoms or p_batch.shape[0] != num_atoms:
            raise ValueError(f"Number of atoms in forces ({f_batch.shape[0]}) or positions ({p_batch.shape[0]}) batch does not match expected number {num_atoms}.")
        if f_batch.shape[1] != 3 or p_batch.shape[1] != 3:
            raise ValueError(f"Force vectors should have 3 components, but got {f_batch.shape[2]} for forces and {p_batch.shape[2]} for positions.")

        # increment count and do energy and forces updates
        count += 1
        energy_mean, energy_M2 = welford_update(e_batch[0], energy_mean, energy_M2, count) # [0] because energy is a scalar
        forces_mean, forces_M2 = welford_update(f_batch, forces_mean, forces_M2, count)
        positions_mean, positions_M2 = welford_update(p_batch, positions_mean, positions_M2, count)

    # Finalize
    energy_var  = energy_M2 / count
    energy_std  = torch.sqrt(energy_var)

    forces_var  = forces_M2 / count
    forces_std  = torch.sqrt(forces_var)

    positions_var = positions_M2 / count
    positions_std = torch.sqrt(positions_var)

    stats = {
        "energy_mean": energy_mean,
        "energy_std": energy_std,
        "forces_mean": forces_mean,
        "forces_std": forces_std,
        "positions_mean": positions_mean,
        "positions_std": positions_std
    }

    return stats

def welford_update(x, mean, M2, count) -> tuple:
    """
    Perform a Welford update for mean and variance.
    Args:
        x (torch.Tensor): The new data point to update the mean and variance with.
        mean (torch.Tensor): The current mean value.
        M2 (torch.Tensor): The current second moment (sum of squares).
        count (int): The current count of data points.
    Returns:
        tuple: Updated mean and second moment (M2).
    """
    delta = x - mean
    mean += delta / count
    delta2 = x - mean
    M2   += delta * delta2
    return mean, M2

def check_means_and_stds(stats: dict, num_atoms: int, device: torch.device):
    """
    Check if the computed means and standard deviations are as expected.
    Args:
        stats (dict): A dictionary containing the mean and standard deviation of energies and forces.
        num_atoms (int): Number of atoms in the system.
        device (torch.device): The device to perform computations on (CPU or GPU).
    Raises:
        AssertionError: If the means and standard deviations do not match the expected values.
    """
    assert torch.isclose(stats['energy_mean'], torch.tensor(0.0, dtype=torch.float64, device=device)), f"Energy mean != 0: {stats['energy_mean']:.6f}"
    assert torch.isclose(stats['energy_std'], torch.tensor(1.0, dtype=torch.float64, device=device)), f"Energy std != 1: {stats['energy_std']:.6f}"
    assert torch.allclose(stats['forces_mean'], torch.zeros((num_atoms, 3), dtype=torch.float64, device=device)), f"Forces mean != 0: {stats['forces_mean'].abs().max():.3e}"
    assert torch.allclose(stats['forces_std'], torch.ones((num_atoms, 3), dtype=torch.float64, device=device)), f"Forces std != 1: {stats['forces_std'].abs().max():.3e}"
    assert torch.allclose(stats['positions_mean'], torch.zeros((num_atoms, 3), dtype=torch.float64, device=device)), f"Positions mean != 0: {stats['positions_mean'].abs().max():.3e}"
    assert torch.allclose(stats['positions_std'], torch.ones((num_atoms, 3), dtype=torch.float64, device=device)), f"Positions std != 1: {stats['positions_std'].abs().max():.3e}"

def save_means_and_stds(save_path: str, stats: dict):
    """
    Save the computed means and standard deviations to a file.
    Args:
        save_path (str): The path to the file where means and standard deviations will be saved.
        stats (dict): A dictionary containing the mean and standard deviation of energies and forces.
    """
    
    torch.save({
        "energy_mean": stats['energy_mean'],
        "energy_std": stats['energy_std'],
        "forces_mean": stats['forces_mean'],
        "forces_std": stats['forces_std'],
        "positions_mean": stats['positions_mean'],
        "positions_std": stats['positions_std']
    }, save_path)
    logger.info(f"Means and standard deviations saved to {save_path}")

def main(trajectory_dir: str, fold: int, num_atoms: int):
    # Setup 
    data_prefix = set_data_prefix()
    # SchNetPack seems to load data not only with GPU, but also with CPU, so we set the device to CPU
    device = torch.device("cpu")
    means_stds_path = os.path.join(data_prefix, trajectory_dir, f"means_stds_fold_{fold}.pt")
    
    if not os.path.exists(means_stds_path):
        logger.info(f"Means and standard deviations file does not exist, computing them")
        stats = load_data_and_compute_stats(
            data_prefix=data_prefix,
            trajectory_dir=trajectory_dir,
            device=device,
            fold=fold,
            num_atoms=num_atoms
        )
    else:
        logger.info(f"Means and standard deviations file exists, loading them")
        stats = torch.load(means_stds_path, map_location=device, weights_only=True)
        print(f"stats: {stats}")
        

    standardized_stats = load_transformed_data_and_compute_stats(
        data_prefix=data_prefix,
        trajectory_dir=trajectory_dir,
        device=device,
        num_atoms=num_atoms,
        stats=stats
    )

    # check if means are zero and stds are one
    check_means_and_stds(standardized_stats, num_atoms, device)

    if not os.path.exists(means_stds_path):
        # Save the computed means and stds to a file
        save_means_and_stds(
            save_path=means_stds_path,
            stats=stats
        )

if __name__ == "__main__":
    args = parse_args()
    main(**args)