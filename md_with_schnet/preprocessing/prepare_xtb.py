import os
import numpy as np
import argparse

from ase import Atoms
from schnetpack.data import ASEAtomsData
from io import StringIO
from ase.data import atomic_numbers as ase_atomic_numbers

from md_with_schnet.utils import set_data_prefix
from md_with_schnet.setup_logger import setup_logger


logger = setup_logger(logging_level_str="debug")


# Example command to run the script from within code directory:
"""
python -m md_with_schnet.preprocessing.prepare_xtb --trajectory_dir MOTOR_MD_XTB/T300_1
"""

def parse_args() -> dict:
    """ 
    Parse command-line arguments. 
    Returns:
        dict: Dictionary containing command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Prepare XTB data for usage in SchNetPack")
    parser.add_argument("--trajectory_dir", type=str, default="MOTOR_MD_XTB/T300_1", help="Directory containing the trajectory data generated by Turbomole (default: MOTOR_MD_XTB/T300_1)")
    return vars(parser.parse_args())

def extract_data_from_xyz(path: str, extra_lines: int, usecols: tuple, number_of_atoms: int | None = None) -> tuple:
    """
    Extract data from a .xyz file and return the coordinates.
    Args:
        path (str): Path to the .xyz file.
        extra_lines (int): Number of extra lines in each coordinates block, e.g., header lines.
    Returns:
        np.ndarray: Array of coordinates for different time steps.
    """
    # Read the file line by line
    with open(path, 'r') as file:
        lines = file.readlines()
        if number_of_atoms is None:
            # If number_of_atoms is not provided, read it from the first line
            number_of_atoms = int(lines[0].strip())

    # Parameters
    logger.debug(f'number_of_atoms: {number_of_atoms}')
    frame_size = number_of_atoms + extra_lines  # Total lines per frame

    # Extract atom data lines
    atom_lines = []
    for i in range(0, len(lines), frame_size):
        # Each frame consists of n header lines and the atom data lines
        atom_data = lines[i + extra_lines:i + extra_lines + number_of_atoms]
        atom_lines.extend(atom_data)

    # Convert the atom data lines into a NumPy array
    atom_data_str = ''.join(atom_lines)
    data = np.loadtxt(StringIO(atom_data_str), usecols=usecols)  # Use the specified columns
    # Reshape the trajectory data
    data = data.reshape(-1, number_of_atoms, 3)  # Shape: (Nframes, Natoms, 3)
    logger.debug(f'data.shape: {data.shape}')
    return data, number_of_atoms

def get_atomic_numbers_from_xyz(path: str, number_of_atoms: int, extra_lines: int = 2) -> list:
    """
    Extract atomic symbols from a .xyz file and convert them to atomic numbers.
    Args:
        path (str): Path to the .xyz file.
        number_of_atoms (int): Number of atoms in the system.
        extra_lines (int): Number of extra lines in each coordinates block, e.g., header lines.
    Returns:
        list: List of atomic numbers.
    """
    with open(path, 'r') as file:
        lines = file.readlines()
        atom_lines = lines[extra_lines:extra_lines + number_of_atoms]  # Skip the first two lines
        symbols = [line.split()[0] for line in atom_lines]
    logger.debug(f'symbols: {symbols}')

    # Convert symbols to atomic numbers
    atomic_numbers = [ase_atomic_numbers[symbol] for symbol in symbols]
    logger.debug(f'atomic_numbers: {atomic_numbers}')

    if len(atomic_numbers) != number_of_atoms:
        logger.error(f'Error: Number of atomic_numbers extracted ({len(atomic_numbers)}) does not match the expected number of atoms ({number_of_atoms}).')
        raise ValueError('Number of atomic_numbers does not match the expected number of atoms.')
    
    return atomic_numbers

def get_all_energies_from_txt(path: str, traj: np.ndarray) -> np.ndarray:
    """
    Extract all (potential) energies from a .txt file and return them as a NumPy array.
    Args:
        path (str): Path to the .txt file.
        traj (np.ndarray): Trajectory data needed for shape validation.
    Returns:
        np.ndarray: Array of energies.
    """
    all_energies = np.loadtxt(path, usecols=(3))   # 3rd column is potential energy
    logger.debug(f'all_energies.shape: {all_energies.shape}')
    if all_energies.shape[0] != traj.shape[0]:
        logger.error(f'Error: all_energies.shape[0] != traj.shape[0]: {all_energies.shape[0]} != {traj.shape[0]}')
        raise ValueError('all_energies.shape[0] != traj.shape[0]')
    return all_energies

def get_all_forces_from_txt(path: str, number_of_atoms: int, number_of_samples: int) -> np.ndarray:
    """
    Extract all gradients from a .txt file, convert them to forces and return them as a NumPy array.
    Args:
        path (str): Path to the .txt file.
        number_of_atoms (int): Number of atoms in the system.
        number_of_samples (int): Number of samples to extract.
    Returns:
        np.ndarray: Array of forces.
    """
    logger.debug("extracting gradients data from txt file")
    # gradients.txt does not contain atomic symbols -> usecols=(0, 1, 2)
    grads = extract_data_from_xyz(path=path, extra_lines=1, usecols=(0, 1, 2), number_of_atoms=number_of_atoms)
    # only take number_of_samples samples
    grads = grads[0][:number_of_samples]
    logger.debug(f'grads.shape after throwing away the last samples not present in traj.xyz: {grads.shape}')
    # convert grads to forces
    forces_traj = -grads
    return forces_traj

def get_all_velocities_from_txt(path: str, number_of_atoms: int, number_of_samples: int) -> np.ndarray:
    """
    Extract all velocities from a .txt file and return them as a NumPy array.
    Args:
        path (str): Path to the .txt file.
        number_of_atoms (int): Number of atoms in the system.
        number_of_samples (int): Number of samples to extract.
    Returns:
        np.ndarray: Array of velocities.
    """
    logger.debug("extracting velocities data from txt file")
    # velocities.txt does contain atomic symbols -> usecols=(1, 2, 3)
    vels = extract_data_from_xyz(path=path, extra_lines=1, usecols=(1, 2, 3), number_of_atoms=number_of_atoms)
    # only take number_of_samples samples
    vels = vels[0][:number_of_samples]
    logger.debug(f'vels.shape after throwing away the last samples not present in traj.xyz: {vels.shape}')
    return vels

def convert_trajectory_to_ase(coords_traj: np.ndarray, energy_traj: np.ndarray, 
                              forces_traj: np.ndarray, velocities_traj: np.ndarray, atomic_numbers: list) -> tuple:
    """
    Convert trajectory data to ASE Atoms objects and properties.
    Args:
        coords_traj (np.ndarray): Coordinates of the trajectory.
        energy_traj (np.ndarray): Energies of the trajectory.
        forces_traj (np.ndarray): Forces of the trajectory.
        velocities_traj (np.ndarray): Velocities of the trajectory.
        atomic_numbers (list): List of atomic numbers.
    Returns:
        tuple: Tuple containing a list of ASE Atoms objects and a list of properties.
    """
    logger.debug("Converting trajectory data to ASE Atoms objects and properties")
    atoms_list = []
    property_list = []
    for positions, energies, forces, velocities in zip(coords_traj, energy_traj, forces_traj, velocities_traj):
        ats = Atoms(positions=positions, numbers=atomic_numbers)
        # convert energies to array if it is not already
        if not isinstance(energies, np.ndarray):
            energies = np.array([energies]) # compare with shape of data within the tutorial

        properties = {'energy': energies, 'forces': forces, 'velocities': velocities}
        property_list.append(properties)
        atoms_list.append(ats)
    logger.debug(f'Properties: {property_list[0]}')
    return atoms_list, property_list

def get_overview_of_dataset(new_dataset: ASEAtomsData):
    """
    Get an overview of the dataset.
    Args:
        new_dataset (ASEAtomsData): The dataset to analyze.
    """
    logger.debug(f'Number of reference calculations: {len(new_dataset)}')
    print('Available properties:')

    for p in new_dataset.available_properties:
        print('-', p)
    print()

    print(f"new_dataset: {new_dataset}")
    example = new_dataset[0]
    print('Properties of molecule with id 0:')

    for k, v in example.items():
        print('-', k, ':', v.shape)

def main(trajectory_dir: str):
    
    # setup paths to the necessary files
    data_prefix = os.path.join(set_data_prefix(), trajectory_dir)
    traj_path = os.path.join(data_prefix, 'coordinates.xyz')
    energy_path = os.path.join(data_prefix, 'energies.txt')
    grads_path = os.path.join(data_prefix, 'gradients.txt')
    vels_path = os.path.join(data_prefix, 'velocities.txt')
    target_path = os.path.join(data_prefix, 'md_trajectory.db')

    if not os.path.exists(traj_path) or not os.path.exists(energy_path) or not os.path.exists(grads_path) or not os.path.exists(vels_path):
        logger.error(f"One or more files do not exist in the specified directory: {data_prefix}")
        raise FileNotFoundError(f"One or more files do not exist in the specified directory: {data_prefix}\n"
                                "Try running log2x > coordinates.xyz, log2egy > energies.txt and the extract.py script in the same directory.")

    logger.debug("Extracting data from .xyz and .txt files")
    coords_traj, number_of_atoms = extract_data_from_xyz(traj_path, usecols=(1, 2, 3), extra_lines=2)
    number_of_samples = coords_traj.shape[0]
    atomic_numbers = get_atomic_numbers_from_xyz(traj_path, number_of_atoms, extra_lines=2)
    energy_traj = get_all_energies_from_txt(energy_path, coords_traj)
    forces_traj = get_all_forces_from_txt(grads_path, number_of_atoms, number_of_samples)
    velocities_traj = get_all_velocities_from_txt(vels_path, number_of_atoms, number_of_samples)

    # convert trajectory data to ASE Atoms objects and properties
    atoms_list, property_list = convert_trajectory_to_ase(coords_traj, energy_traj, forces_traj, velocities_traj, atomic_numbers)

    # Create a new dataset in the schnetpack format
    if os.path.exists(target_path):
        print(f"File {target_path} already exists, loading it.")
        new_dataset = ASEAtomsData(target_path)
    else:
        print(f"File {target_path} does not exist, creating it.")
        # create a new dataset
        new_dataset = ASEAtomsData.create(
            target_path, 
            distance_unit='Ang',
            property_unit_dict={
                'energy':'Hartree', 
                'forces':'Hartree/Bohr', 
                'velocities':'Bohr/atomic_time_unit'
                },
        )
        # add systems to the dataset
        new_dataset.add_systems(property_list, atoms_list)

    # get overview of the dataset
    get_overview_of_dataset(new_dataset)

if __name__=="__main__":
    args = parse_args()
    main(**args)