import os
import numpy as np
import argparse

from ase import Atoms
from schnetpack.data import ASEAtomsData
from ase.data import atomic_numbers as ase_atomic_numbers

from md_with_schnet.utils import set_data_prefix
from md_with_schnet.setup_logger import setup_logger


logger = setup_logger(logging_level_str="debug")


# Example command to run the script from within code directory:
"""
python -m md_with_schnet.preprocessing.prepare_xtb --trajectory_dir MOTOR_MD_XTB/T300_1 --num_atoms 48
"""

def parse_args() -> dict:
    """ 
    Parse command-line arguments. 
    Returns:
        dict: Dictionary containing command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Prepare XTB data for usage in SchNetPack")
    parser.add_argument("--trajectory_dir", type=str, default="MOTOR_MD_XTB/T300_1", help="Directory containing the trajectory data generated by Turbomole (default: MOTOR_MD_XTB/T300_1)")
    parser.add_argument('--num_atoms', type=int, required=True, help='Number of atoms in the simulation. Can be found in the "control" file under "natoms".')
    return vars(parser.parse_args())

def get_atomic_numbers_from_xyz(path: str, number_of_atoms: int, extra_lines: int) -> list:
    """
    Extract atomic symbols from a .xyz file and convert them to atomic numbers.
    Args:
        path (str): Path to the .xyz file.
        number_of_atoms (int): Number of atoms in the system.
        extra_lines (int): Number of extra lines in each coordinates block, e.g., header lines.
    Returns:
        list: List of atomic numbers.
    """
    with open(path, 'r') as file:
        lines = file.readlines()
        atom_lines = lines[extra_lines:extra_lines + number_of_atoms]  # Skip the first n lines
        symbols = [line.split()[0] for line in atom_lines]
    logger.debug(f'symbols: {symbols}')

    # Convert symbols to atomic numbers
    atomic_numbers = [ase_atomic_numbers[symbol] for symbol in symbols]
    logger.debug(f'atomic_numbers: {atomic_numbers}')

    if len(atomic_numbers) != number_of_atoms:
        raise ValueError(f"Number of atomic_numbers extracted ({len(atomic_numbers)}) does not match the expected number of atoms ({number_of_atoms}).")
    
    return atomic_numbers

def get_all_energies_from_txt(path: str) -> tuple:
    """
    Extract all (potential) energies from a .txt file and return them as a NumPy array.
    Args:
        path (str): Path to the .txt file.
    Returns:
        tuple: Tuple containing all energies and the number of samples.
    """
    all_energies = np.loadtxt(path, usecols=(3))   # 3rd column is potential energy
    number_of_samples = all_energies.shape[0]
    logger.debug(f'all_energies.shape: {all_energies.shape}')
    logger.debug(f'number_of_samples: {number_of_samples}')
    return all_energies, number_of_samples

def get_trajectory_from_txt_and_reshape(path: str, number_of_samples: int, 
                                        num_atoms: int, usecols: tuple[int] = (1, 2, 3)) -> np.ndarray:
    """
    Load trajectory data from a .txt file and reshape it to the desired format.
    Args:
        path (str): Path to the .txt file containing trajectory data.
        number_of_samples (int): Number of samples to align with.
        num_atoms (int): Number of atoms in the system.
        usecols (tuple[int]): Columns to use from the .txt file. Default is (1, 2, 3) which skips the element symbols.
    Returns:
        np.ndarray: Reshaped trajectory data with shape (Nframes, Natoms, 3).
    """
    traj = np.loadtxt(path, usecols=usecols, comments=["#", "t="]) 
    traj = traj.reshape(-1, num_atoms, 3)  # Shape: (Nframes, Natoms, 3)
    traj = align_shapes(number_of_samples, traj)
    return traj


def align_shapes(number_of_samples: int, traj: np.ndarray) -> np.ndarray:
    """
    Align the shape of the trajectory data with the number of samples given by the energy trajectory.
    Args:
        number_of_samples (int): Number of samples to align with.
        traj (np.ndarray): Trajectory data to align.
    Returns:
        np.ndarray: Aligned trajectory data.
    """
    if traj.shape[0] != number_of_samples:
        logger.warning(f'traj.shape[0] != number_of_samples: {traj.shape[0]} != {number_of_samples}')
        logger.warning("Just using the first number_of_samples samples from grads_traj")
        traj = traj[:number_of_samples]
    return traj

def convert_trajectory_to_ase(coords_traj: np.ndarray, energy_traj: np.ndarray, 
                              forces_traj: np.ndarray, velocities_traj: np.ndarray, atomic_numbers: list) -> tuple:
    """
    Convert trajectory data to ASE Atoms objects and properties.
    Args:
        coords_traj (np.ndarray): Coordinates of the trajectory.
        energy_traj (np.ndarray): Energies of the trajectory.
        forces_traj (np.ndarray): Forces of the trajectory.
        velocities_traj (np.ndarray): Velocities of the trajectory.
        atomic_numbers (list): List of atomic numbers.
    Returns:
        tuple: Tuple containing a list of ASE Atoms objects and a list of properties.
    """
    logger.debug("Converting trajectory data to ASE Atoms objects and properties")
    atoms_list = []
    property_list = []
    for positions, energies, forces, velocities in zip(coords_traj, energy_traj, forces_traj, velocities_traj):
        ats = Atoms(positions=positions, numbers=atomic_numbers)
        # convert energies to array if it is not already
        if not isinstance(energies, np.ndarray):
            energies = np.array([energies]) # compare with shape of data within the tutorial

        properties = {'energy': energies, 'forces': forces, 'velocities': velocities}
        property_list.append(properties)
        atoms_list.append(ats)
    logger.debug(f'Properties: {property_list[0]}')
    return atoms_list, property_list

def get_overview_of_dataset(new_dataset: ASEAtomsData):
    """
    Get an overview of the dataset.
    Args:
        new_dataset (ASEAtomsData): The dataset to analyze.
    """
    logger.debug(f'Number of reference calculations: {len(new_dataset)}')
    print('Available properties:')

    for p in new_dataset.available_properties:
        print('-', p)
    print()

    print(f"new_dataset: {new_dataset}")
    example = new_dataset[0]
    print('Properties of molecule with id 0:')

    for k, v in example.items():
        print('-', k, ':', v.shape)

def main(trajectory_dir: str, num_atoms: int):
    """
    Main function to prepare XTB data for usage in SchNetPack.
    We prepare it completely in atomic units, which is the output from Turbomole for its log files.
    Args:
        trajectory_dir (str): Directory containing the trajectory data generated by Turbomole.
        num_atoms (int): Number of atoms in the simulation. Can be found in the "control" file under "natoms".
    """
    logger.debug("Starting to prepare XTB data for SchNetPack")
    # setup paths to the necessary files
    data_prefix = os.path.join(set_data_prefix(), trajectory_dir)
    traj_path = os.path.join(data_prefix, 'positions.txt')
    energy_path = os.path.join(data_prefix, 'energies.txt')
    grads_path = os.path.join(data_prefix, 'gradients.txt')
    vels_path = os.path.join(data_prefix, 'velocities.txt')
    target_path = os.path.join(data_prefix, 'md_trajectory_atomic_units.db')

    if not os.path.exists(traj_path) or not os.path.exists(energy_path) or not os.path.exists(grads_path) or not os.path.exists(vels_path):
        logger.error(f"One or more files do not exist in the specified directory: {data_prefix}")
        raise FileNotFoundError(f"One or more files do not exist in the specified directory: {data_prefix}\n"
                                "Try running log2egy > energies.txt and the extract.py script for the different properties in the same directory.")

    logger.debug("Extracting data from .txt files")
    energy_traj, number_of_samples  = get_all_energies_from_txt(energy_path)
    coords_traj = get_trajectory_from_txt_and_reshape(traj_path, number_of_samples, num_atoms, usecols=(1, 2, 3))
    grads_traj = get_trajectory_from_txt_and_reshape(grads_path, number_of_samples, num_atoms, usecols=(0, 1, 2))
    forces_traj = -grads_traj  # Convert gradients to forces
    velocities_traj = get_trajectory_from_txt_and_reshape(vels_path, number_of_samples, num_atoms, usecols=(1, 2, 3))
    atomic_numbers = get_atomic_numbers_from_xyz(traj_path, num_atoms, extra_lines=3)

    # convert trajectory data to ASE Atoms objects and properties
    atoms_list, property_list = convert_trajectory_to_ase(coords_traj, energy_traj, forces_traj, velocities_traj, atomic_numbers)

    # Create a new dataset in the schnetpack format
    if os.path.exists(target_path):
        logger.info(f"File {target_path} already exists, loading it.")
        new_dataset = ASEAtomsData(target_path)
    else:
        logger.info(f"File {target_path} does not exist, creating it.")
        # create a new dataset
        new_dataset = ASEAtomsData.create(
            target_path, 
            distance_unit='Bohr',
            property_unit_dict={
                'energy':'Hartree', 
                'forces':'Hartree/Bohr', 
                'velocities':'Bohr/atomic_time_unit'
                },
        )
        # add systems to the dataset
        new_dataset.add_systems(property_list, atoms_list)

    # get overview of the dataset
    get_overview_of_dataset(new_dataset)

if __name__=="__main__":
    args = parse_args()
    main(**args)