import os
import pytorch_lightning as pl
import argparse
import time

from hydra.utils import instantiate, get_class
from omegaconf import OmegaConf, DictConfig


# own imports
from md_with_schnet.utils import setup_logger, set_data_prefix, get_split_path, load_config, setup_datamodule, get_num_workers
from md_with_schnet.units import get_ase_units_from_str, convert_distances

logger = setup_logger("debug")

# Example command to run the script from within code directory:
"""
screen -dmS xtb_train sh -c 'python -m md_with_schnet.training_and_inference.train --trajectory_dir MOTOR_MD_XTB/T300_1 -e 1 -cname train_config_default_transforms --units angstrom_kcal_per_mol_fs; exec bash'
"""

def parse_args() -> dict:
    """ 
    Parse command-line arguments. 
    Returns:
        dict: Dictionary containing command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Script for training SchNetPack on XTB datasets.")
    # paths setup
    parser.add_argument("--trajectory_dir", type=str, default="MOTOR_MD_XTB/T300_1", help="Directory containing the trajectory data generated by Turbomole (relative to the data directory) (default: MOTOR_MD_XTB/T300_1)")
    parser.add_argument("--units", type=str, default="angstrom_kcal_per_mol_fs", choices=["angstrom_kcal_per_mol_fs", "angstrom_ev_fs", "angstrom_hartree_fs", "bohr_hartree_aut"], help="Units for the input data (default: angstrom_kcal_per_mol_fs).")
    # training setup
    parser.add_argument("-bs", "--batch_size", type=int, default=100, help="Batch size for training (default: 100)")
    parser.add_argument("-e", "--num_epochs", type=int, default=1, help="Number of epochs for training (default: 1)")
    parser.add_argument("-lr", "--learning_rate", type=float, default=1e-4, help="Learning rate for the optimizer (default: 1e-4)")
    parser.add_argument("-flw", "--forces_loss_weight", type=float, default=0.99, help="Weight for the forces loss (default: 0.99). Default value works well for angstrom_kcal_per_mol_fs units, but may need to be adjusted for other units. Note that, they do NOT need to sum to 1.0 (see notes on change of units).")
    parser.add_argument("-elw", "--energy_loss_weight", type=float, default=0.01, help="Weight for the energy loss (default: 0.01). Default value works well for angstrom_kcal_per_mol_fs units, but may need to be adjusted for other units. Note that, they do NOT need to sum to 1.0 (see notes on change of units).")
    parser.add_argument("-nw", "--num_workers", type=int, default=-1, help="Number of workers for data loading (default: -1, which sets it to 0 on macOS and 8 on Linux)")
    # others
    parser.add_argument("-cname", "--config_name", type=str, default="train_config", help="Name of the configuration file (default: train_config)")
    parser.add_argument("-f", "--fold", type=int, default=0, help="Fold number for cross-validation (default: 0)")
    parser.add_argument("-s", "--seed", type=int, default=42, help="Random seed for reproducibility (default: 42)")
    return vars(parser.parse_args())

def get_data_paths(data_prefix: str, trajectory_dir: str, fold: int, units: str) -> tuple:
    """ 
    Get the paths to the database and statistics files.
    Args:
        data_prefix (str): Prefix for the data directory.
        trajectory_dir (str): Directory containing the trajectory data.
        fold (int): Fold number for cross-validation.
    Returns:
        tuple: Paths to the database and statistics files.
    """
    path_to_traj_dir = os.path.join(data_prefix, trajectory_dir)
    path_to_db = os.path.join(path_to_traj_dir, f"md_trajectory_{units}.db")
    path_to_stats = os.path.join(path_to_traj_dir, f"means_stds_fold_{units}_{fold}.pt")
    return path_to_db, path_to_stats

def set_run_path(trajectory_dir: str, units: str, num_epochs: int, batch_size: int, learning_rate: float, forces_loss_weight: float, energy_loss_weight: float, seed: int) -> str:
    """ 
    Set the run path based on the trajectory directory.
    Args:
        trajectory_dir (str): Directory containing the trajectory data.
        units (str): Units for the input data.
        num_epochs (int): Number of epochs for training.
        batch_size (int): Batch size for training.
        learning_rate (float): Learning rate for the optimizer.
        forces_loss_weight (float): Weight for the forces loss.
        energy_loss_weight (float): Weight for the energy loss.
        seed (int): Random seed for reproducibility.
    Returns:
        str: The run path.
    """
    current_dir = os.path.dirname(os.path.abspath(__file__))
    run_name = f"epochs_{num_epochs}_bs_{batch_size}_lr_{learning_rate}_flw_{forces_loss_weight}_elw_{energy_loss_weight}_seed_{seed}"
    run_path = os.path.join(current_dir, "runs", units, trajectory_dir, run_name)
    return run_path

def update_config(cfg: DictConfig, run_path: str, ase_units: dict, batch_size: int, num_epochs: int, learning_rate: float, forces_loss_weight: float, energy_loss_weight: float, num_workers: int, path_to_stats: str) -> DictConfig:
    """ 
    Update the configuration with command-line arguments.
    Args:
        cfg (DictConfig): The original configuration.
        run_path (str): Path to save the run.
        ase_units (dict): Dictionary containing ASE units.
        batch_size (int): Batch size for training.
        num_epochs (int): Number of epochs for training.
        learning_rate (float): Learning rate for the optimizer.
        forces_loss_weight (float): Weight for the forces loss.
        energy_loss_weight (float): Weight for the energy loss.
        num_workers (int): Number of workers for data loading.
        path_to_stats (str): Path to the statistics file (mean and std) for standardization.
    Returns:
        DictConfig: Updated configuration.
    """
    cfg.run.path = run_path
    cfg.run.mean_std_path = path_to_stats
    cfg.data.batch_size = batch_size
    cfg.data.num_workers = get_num_workers(num_workers)
    cfg.trainer.max_epochs = num_epochs
    cfg.globals.lr = learning_rate

    if cfg.task.outputs[0].name != cfg.globals.energy_key or cfg.task.outputs[1].name != cfg.globals.forces_key:
        raise ValueError(f"The task outputs names must be '{cfg.globals.energy_key}' and '{cfg.globals.forces_key}'. Please check your configuration file.")
    else:
        cfg.task.outputs[0].loss_weight = energy_loss_weight
        cfg.task.outputs[1].loss_weight = forces_loss_weight

    # Set the ASE units in the configuration
    cfg.data.distance_unit = ase_units['distance']
    cfg.data.property_units.energy = ase_units['energy']
    cfg.data.property_units.forces = ase_units['forces']

    # If using Bohr, convert the cutoff distance from Angstrom to Bohr
    if ase_units['distance'] == "Bohr":
        cfg.globals.cutoff = convert_distances(cfg.globals.cutoff, "angstrom", "bohr")
    return cfg



def main(trajectory_dir: str, units: str, batch_size: int, num_epochs: int, learning_rate: float, 
         forces_loss_weight: float, energy_loss_weight: float, num_workers: int, config_name: str, fold: int, seed: int):
    ####################### Basic setup ###########################
    pl.seed_everything(seed, workers=True)
    data_prefix = set_data_prefix()
    split_file = get_split_path(data_prefix, trajectory_dir, fold)
    path_to_db, path_to_stats = get_data_paths(data_prefix, trajectory_dir, fold, units)
    logger.info(f"Using the following units: {units}")

    ####################### 1) Compose the config ###########################
    cfg = load_config(f"training_and_inference/conf", config_name, "train")

    # set run path
    run_path = set_run_path(trajectory_dir, units, num_epochs, batch_size, learning_rate, forces_loss_weight, energy_loss_weight, seed)
    logger.debug(f"Run path: {run_path}")
    
    # update the config with the arguments from the command line
    ase_units = get_ase_units_from_str(units)
    cfg = update_config(cfg, run_path, ase_units, batch_size, num_epochs, learning_rate, 
                        forces_loss_weight, energy_loss_weight, num_workers, path_to_stats)
    logger.info(f"Loaded and updated config:\n{OmegaConf.to_yaml(cfg)}")

    ####################### 2) Switch strings to classes ####################
    optim_cls = get_class(cfg.task.optimizer_cls)  
    sched_cls = get_class(cfg.task.scheduler_cls)

    ####################### 3) Prepare our own data #########################
    datamodule = setup_datamodule(cfg.data, path_to_db, split_file)

    ####################### 4) Instantiate model & task from YAML ###########
    model: pl.LightningModule = instantiate(cfg.model)
    task: pl.LightningModule = instantiate(
        cfg.task,
        model=model,
        optimizer_cls=optim_cls,
        scheduler_cls=sched_cls
    )

    ####################### 5) Logger ################################
    # Convert the config to a basic dict with resolved values, i.e. ${work_dir} -> /path/to/work_dir
    used_config = OmegaConf.to_container(cfg, resolve=True)

    # instantiate the logger
    tb_logger = instantiate(cfg.logger.tensorboard)

    # Manually log your clean hyperparameters
    tb_logger.log_hyperparams(used_config) # saves as hparams.yaml (difficult to change)

    # Prevent Lightning from auto‐saving used_config (no‐op override)
    # use lambda function taking any number of arguments and returning None
    tb_logger.log_hyperparams = lambda *args, **kwargs: None


    ####################### 6) Callbacks ##############################
    callbacks = [
        instantiate(cfg.callbacks.model_checkpoint),
        instantiate(cfg.callbacks.early_stopping),
        instantiate(cfg.callbacks.lr_monitor),
        instantiate(cfg.callbacks.ema),
    ]

    ####################### 7) Trainer ################################
    trainer: pl.Trainer = instantiate(
        cfg.trainer,
        callbacks=callbacks,
        logger=tb_logger,
        deterministic=True, # for reproducibility
    )

    
    ####################### 8) Launch training ########################
    # since we have a pl datamodule, it is split automatically into train, val and test sets
    # depending on which method is called, e.g. fit, validate, test
    # see https://lightning.ai/docs/pytorch/stable/data/datamodule.html for more details
    trainer.fit(task, datamodule=datamodule)

if __name__ == "__main__":
    args = parse_args()
    start = time.time()
    main(**args)
    print(f"Total time: {time.time() - start:.2f} seconds")


# TIMINGS 5 EPOCHS (on pc38)
# MOTOR_MD_XTB/T300_1 with roughly 13000 training samples

# Batch size: 100
# num_workers: 0  - 139.43s
# num_workers: 15 - 18.58s
# num_workers: 31 - 17.40s

# Batch size: 10
# num_workers: 0  - 191.98s
# num_workers: 15 - 48.62s
# num_workers: 31 - 50.66s (and led to errors sometimes)

# Now its somehow much slower, even with 31 workers

# TIMING 1000 EPOCHS (on pc54)
# MOTOR_MD_XTB/T300_1 with 12615 training samples, bs=100, num_workers=31
# Total time: 20825.10 seconds = 5.78 hours