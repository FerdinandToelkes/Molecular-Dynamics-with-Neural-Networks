import os
import argparse
import schnetpack as spk
import platform
import time
import schnetpack.transform as trn
import logging
import torch
import pytorch_lightning as pl

from hydra import initialize, compose
from omegaconf import OmegaConf, DictConfig
from ase import Atoms
# from ase.md.velocitydistribution import MaxwellBoltzmannDistribution
from ase.md.verlet import VelocityVerlet as ASEVelocityVerlet
from ase import units
from ase.io import read, write
from xtb_ase import XTB
from tqdm import tqdm

from md_with_schnet.utils import set_data_prefix
from md_with_schnet.setup_logger import setup_logger


# Example command to run the script from within code directory:
"""
screen -dmS inference_xtb sh -c 'python -m md_with_schnet.neural_net.inference_with_ase --md_steps 10 ; exec bash'
"""


logger = setup_logger("debug")

def parse_args() -> dict:
    """ Parse command-line arguments. 

    Returns:
        dict: Dictionary containing command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Script for predicting with trained model on XTB test data.")
    # paths setup
    parser.add_argument("--trajectory_dir", type=str, default="MOTOR_MD_XTB/T300_1", help="Directory containing the trajectory data generated by Turbomole (default: MOTOR_MD_XTB/T300_1)")
    parser.add_argument("-mdir", "--model_dir", type=str, default="MOTOR_MD_XTB_T300_1_epochs_1000_bs_100_lr_0.0001_seed_42", help="Directory of the trained model (default: MOTOR_MD_XTB_T300_1_epochs_1000_bs_100_lr_0.0001_seed_42)")
    parser.add_argument("-mds", "--md_steps", type=int, default=10, help="Number of MD steps to run (default: 10)")
    parser.add_argument("-ts", "--time_step", type=float, default=0.5, help="Time step for the MD simulation in fs (default: 0.5 fs)")
    parser.add_argument("-s", "--seed", type=int, default=42, help="Random seed for reproducibility (default: 42)")
    parser.add_argument("-nw", "--num_workers", type=int, default=-1, help="Number of workers for data loading (default: -1, which sets it to 0 on macOS and 8 on Linux)")
    return vars(parser.parse_args())

def get_split_path(data_prefix: str, trajectory_dir: str, fold: int = 0) -> str:
    """
    Get the path to the split file for the given trajectory directory and fold.
    Args:
        data_prefix (str): The prefix path to the data directory.
        trajectory_dir (str): The directory containing the trajectory data.
        fold (int): The fold number for cross-validation (default: 0).
    Returns:
        str: The path to the split file.
    """
    split_file = os.path.join(data_prefix, "splits", trajectory_dir, f"inner_splits_{fold}.npz")
    if not os.path.exists(split_file):
        raise FileNotFoundError(f"Missing split file: {split_file}")
    logger.debug(f"Split file: {split_file}")
    return split_file

def prepare_and_load_data(data_prefix: str, cfg: DictConfig, trajectory_dir: str) -> pl.LightningDataModule:
    """
    Prepare loading the dataset and then load it.
    Args:
        data_prefix (str): The prefix path to the data directory.
        cfg (DictConfig): The configuration dictionary.
        trajectory_dir (str): The directory containing the trajectory data.
    Returns:
        pl.LightningDataModule: The data module containing the dataset.
    """
    split_file = get_split_path(data_prefix, trajectory_dir, fold=0)

    path_to_db = os.path.join(data_prefix, trajectory_dir, "md_trajectory.db")
    logger.debug(f"Path to database: {path_to_db}")

    datamodule = load_xtb_dataset(path_to_db, cfg, split_file)
    return datamodule

def load_xtb_dataset(db_path: str, config: DictConfig, split_file: str | None = None, pin_memory: bool | None = None) -> spk.data.datamodule.AtomsDataModule:
    """
    Load anXTB dataset from the specified path. 
    Note: data.prepare_data() and data.setup() do not need to be called here, since they will be called by pl.trainer.fit().
    Args:
        db_path (str): Path to the dataset.
        config (DictConfig): Configuration object containing dataset parameters.
        split_file (str | None): Path to the split file. Default is None.
        pin_memory (bool | None): Whether to use pinned memory. Default is None.
    Returns:
        spk.data.datamodule.AtomsDataModule: The loaded XTB dataset.
    """
    if pin_memory is None:
        pin_memory = torch.cuda.is_available()

    if config.data.num_workers == -1:
        num_workers = 0 if platform.system() == "Darwin" else 8 
    else:
        num_workers = config.data.num_workers
    logger.debug(f"pin_memory: {pin_memory}")
    logger.debug(f"num_workers: {num_workers}")

    # load xtb dataset with subclass of pl.LightningDataModule
    data = spk.data.AtomsDataModule(
        db_path,
        batch_size=config.data.batch_size,
        distance_unit='Bohr',
        property_units={'energy':'Hartree', 'forces':'Hartree/Bohr'},
        split_file=split_file,
        transforms=[
            trn.ASENeighborList(cutoff=5.),
            trn.RemoveOffsets("energy", remove_mean=True, remove_atomrefs=False),
            trn.CastTo32()
        ],
        num_workers=num_workers,
        pin_memory=pin_memory, # set to false, when not using a GPU
    )
    data.prepare_data()
    data.setup()
    logger.info(f"loaded xtb dataset: {data}")

    if not isinstance(data, pl.LightningDataModule):
        raise ValueError("The loaded dataset is not an instance of pl.LightningDataModule. Please check the dataset path and configuration.")

    return data

#######################################################################

def update_config_with_train_config(cfg: DictConfig, cfg_train: DictConfig) -> DictConfig:
    """
    Update the configuration with the training configuration to ensure consistency.
    Args:
        cfg (DictConfig): The original configuration.
        cfg_train (DictConfig): The training configuration.
    Returns:
        DictConfig: Updated configuration.
    """
    # Disable struct mode to allow adding new fields
    OmegaConf.set_struct(cfg, False)

    # Copy over specific globals
    cfg.globals.cutoff = cfg_train.globals.cutoff
    cfg.globals.energy_key = cfg_train.globals.energy_key
    cfg.globals.forces_key = cfg_train.globals.forces_key

    # Copy over data fields
    cfg.data = cfg_train.data

    # Re-enable struct mode to enforce the structure
    OmegaConf.set_struct(cfg, True)
    return cfg

def update_config(cfg: DictConfig, run_path: str, md_steps: int, time_step: float, num_workers: int) -> DictConfig:
    """ 
    Update the configuration with command-line arguments.
    Args:
        cfg (DictConfig): The original configuration.
        run_path (str): Path to save the run.
        md_steps (int): Number of MD steps to run.
        time_step (float): Time step for the MD simulation in atomic units.
        num_workers (int): Number of workers for data loading.
    Returns:
        DictConfig: Updated configuration.
    """
    cfg.run.path = run_path
    if num_workers != -1:
        cfg.data.num_workers = num_workers
    else:
        cfg.data.num_workers = 0 if platform.system() == 'Darwin' else 8
    cfg.md.n_steps = md_steps
    cfg.md.time_step = time_step 

    return cfg


def move_xtb_files_to_xtb_dir(xtb_dir: str):
    """
    Move the XTB output files to the specified xtb directory. This is necessary
    because the XTB calculator creates files in the current working directory,
    which may not be the same as the directory where the script is run.
    Args:
        xtb_dir (str): Path to the directory where XTB files should be moved.
    """
    xtb_files = ["charges", "coord.engrad", "coord.xyz", "energy", "gradient", "wbo", 
                 "xtb.inp", "xtb.out", "xtbout.json", "xtbrestart", "xtbtopo.mol"]
    current_dir = os.getcwd()
    for file in xtb_files:
        src = os.path.join(current_dir, file)
        dst = os.path.join(xtb_dir, file)
        if os.path.exists(src):
            os.rename(src, dst)
            logger.info(f"Moved {src} to {dst}")
        else:
            logger.warning(f"File {src} does not exist, skipping move.")

def main(trajectory_dir: str, model_dir: str, md_steps: int, time_step: float, seed: int, num_workers: int):
    ####################### 1) Compose the config ###########################
    with initialize(config_path="conf", job_name="inference", version_base="1.1"):
        cfg: DictConfig = compose(config_name="inference_config")

    # use training config to update the inference config
    train_cfg_path = os.path.join("runs", model_dir, "tensorboard/default/version_0")
    with initialize(config_path=train_cfg_path, job_name="train", version_base="1.1"):
        cfg_train: DictConfig = compose(config_name="hparams.yaml")
    cfg = update_config_with_train_config(cfg, cfg_train)

    # update config with arguments from command line
    home_dir = os.path.expanduser("~")
    model_dir_path = os.path.join(home_dir, "whk/code/md_with_schnet/neural_net/runs", model_dir)
    cfg = update_config(cfg, model_dir_path, md_steps, time_step, num_workers)
    logger.info(f"Loaded and updated config:\n{OmegaConf.to_yaml(cfg)}")

    ####################### 2) Prepare Data and Paths #########################
    data_prefix = set_data_prefix()
    md_workdir = cfg.run.path
    simulation_name = f"md_sim_steps_{md_steps}_time_step_{time_step}_seed_{seed}"
    target_dir = os.path.join(md_workdir, simulation_name)
    xtb_dir = os.path.join(target_dir, "xtb")
    if os.path.exists(target_dir):
        raise FileExistsError(f"Target directory already exists: {target_dir}. Please choose a different name or remove the existing directory.")
    os.makedirs(target_dir)
    os.makedirs(xtb_dir)  
    logger.debug(f"MD workdir: {md_workdir}")

    datamodule = prepare_and_load_data(data_prefix, cfg, trajectory_dir)


    ####################### 4) Prepare molecule ##############################
    structure = datamodule.test_dataset[0]
    
    atoms_xtb = Atoms(
        numbers=structure[spk.properties.Z],
        positions=structure[spk.properties.R],
    )

    velocities_au = structure["velocities"]
    # transform from torch tensor to numpy array 
    if isinstance(velocities_au, torch.Tensor):
        velocities_au = velocities_au.detach().cpu().numpy()
    else:
        raise TypeError(f"Unsupported type for velocities: {type(velocities_au)}")
    

    # convert velocities from atomic units to Angstrom/ase time units
    bohr_to_angstrom = units.Bohr  # 1 Bohr = 0.52917721067 Ã…
    aut_to_s = units._aut
    velocities_ase = velocities_au * bohr_to_angstrom / (aut_to_s * units.s) 
    atoms_xtb.set_velocities(velocities_ase)

    # check if velocities are valid by computing the corresponding temperature
    temperature = atoms_xtb.get_temperature()
    logger.info(f"Initial temperature of the system: {temperature} K")
    e_kin = atoms_xtb.get_kinetic_energy()
    logger.info(f"Initial kinetic energy of the system: {e_kin} eV")    
    

    # make duplicate of the atoms object 
    atoms_nn = atoms_xtb.copy()

    ####################### 6) Setup calculators ##############################
    atoms_xtb.calc = XTB(
        method=cfg.xtb.method,
    )
    
    md_calculator = spk.interfaces.SpkCalculator(
        model_file=cfg.globals.model_path,
        neighbor_list=trn.ASENeighborList(cutoff=cfg.model.neighborlist.cutoff),
        energy_key=cfg.globals.energy_key,
        force_key=cfg.globals.forces_key,
        energy_unit=cfg.data.property_units.energy, # Hartree
        position_unit=cfg.data.distance_unit, # Bohr
    )
    atoms_nn.calc = md_calculator

    ####################### 8) Setup simulator ##############################
     # convert time step from atomic units to seconds and then to ASE time units
    logger.debug(f"Time step (in fs): {cfg.md.time_step}")
    time_step_ase = cfg.md.time_step * units.fs
    logger.debug(f"Time step (in ASE time units): {time_step_ase:.2f}")
    

    dyn_xtb = ASEVelocityVerlet(
        atoms_xtb, 
        timestep=time_step_ase, 
        trajectory=f'{target_dir}/xtb_traj.traj', 
        logfile=f'{target_dir}/xtb_md.log',
    )
         
    dyn_nn = ASEVelocityVerlet(
        atoms_nn, 
        timestep=time_step_ase, 
        trajectory=f'{target_dir}/nn_traj.traj', 
        logfile=f'{target_dir}/nn_md.log',
    )
    

    ####################### 9) Run simulations ##############################
    logger.info(f"Starting simulation with {cfg.md.n_steps} steps and saving to {md_workdir}")
    nn_start = time.time()
    # dyn_nn.run(cfg.md.n_steps)
    nn_end = time.time()
    
    # Create a tqdm progress bar
    pbar = tqdm(total=cfg.md.n_steps, desc="MD progress")

    # Attach a callback that advances the bar once each interval
    def update_bar(_=None):
        pbar.update(interval)  # note: interval defined below

    interval = 1
    dyn_xtb.attach(update_bar, interval=interval)

    # Silence the XTB output to avoid cluttering the console
    logging.getLogger('cclib').setLevel(logging.WARNING)
    xtb_start = time.time()
    dyn_xtb.run(cfg.md.n_steps)
    xtb_end = time.time()
    
    print(f"XTB time: {xtb_end - xtb_start:.2f} s")
    print(f"NN time: {nn_end - nn_start:.2f} s")

    # Move the files created by the XTB calculator to the xtb directory
    move_xtb_files_to_xtb_dir(xtb_dir)

    # read in the saved .traj files and save them as .xyz files
    xtb_traj = read(f'{target_dir}/xtb_traj.traj', index=':')
    nn_traj = read(f'{target_dir}/nn_traj.traj', index=':')
    write(f'{target_dir}/xtb_traj.xyz', xtb_traj)
    write(f'{target_dir}/nn_traj.xyz', nn_traj)

    # ####################### 5) Setup MD system ##############################
    # md_system = System()
    # md_system.load_molecules(
    #     atoms,
    #     n_replicas=cfg.md.n_replicas,
    #     position_unit_input=cfg.model.units.length,
    # )

    # # Initial momenta
    # md_initializer = UniformInit(
    #     cfg.md.system_temperature,
    #     remove_center_of_mass=True,
    #     remove_translation=True,
    #     remove_rotation=True,
    # )
    # md_initializer.initialize_system(md_system)


   


if __name__ == "__main__":
    args = parse_args()
    main(**args)


# TIMINGS
# 10 steps with 0.5 fs time step on pc54
# NN time: 0.77 s
# XTB time: 4.54 s

# 100 steps with 0.5 fs time step on pc54
# NN time: 6.97 s
# XTB time: 42.48 s

# 1000 steps with 1 fs time step on pc54
# NN time: 337.57 s = 5.63 min
# XTB time:  2193.96 s = 36.57 min

# 10000 steps with 0.5 fs time step on pc54
# NN time: Not measured
# XTB time: 4143.98 s