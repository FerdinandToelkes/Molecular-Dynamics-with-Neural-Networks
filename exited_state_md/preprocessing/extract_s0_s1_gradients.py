import os
import argparse

from tqdm import tqdm

from exited_state_md.preprocessing.utils import prepare_last_exited_cycles, set_path_and_remove_old_file
from ground_state_md.utils import set_data_prefix
from ground_state_md.setup_logger import setup_logger

# Example command to run the script from within code directory:
"""
python3 -m exited_md.preprocessing.extract_s0_s1_gradients --target_dir PREPARE_12
"""

# Note: sadly the data is messy :(. The ground state gradients were originally not computed when in the exited S1 state. Now, the gradients for the exited S1 state have been computed, but only for the first 1461 cycles.

# (*) The s0 and s1 gradients are scattered across the gradient, gradient_ex and s0_gradient files. The gradient file contains the gradients of the active state, the gradient_ex file contains the s1 gradients starting from the last exited cycle, and the s0_gradient file contains the gradients of the ground state at least up to the last exited cycle. The s1 gradients are extracted from the gradient file until the last exited cycle and from the gradient_ex file from the last exited cycle to the end of the trajectory. The s0 gradients are extracted from the s0_gradient file until the last exited cycle and the rest is taken from the gradient file. Unfortunately, this is a bit Lionel ...

logger = setup_logger(logging_level_str="info")

def parse_args() -> dict:
    """ Parse command-line arguments. 

    Returns:
        dict: Dictionary containing command-line arguments.
    """
    parser = argparse.ArgumentParser(description="Extract the gradients belonging to the ground state and exited energy for all GEO directories.")
    parser.add_argument("--target_dir", type=str, default="PREPARE_12", help="Directory containing the trajectory data generated by Turbomole (default: PREPARE_12)")
    parser.add_argument("--computed_cycles", type=int, default=1461, help="Number of cycles for which the gradients were computed (default: 1461)")
    parser.add_argument("--total_cycles", type=int, default=3000, help="Total number of cycles that should be in each trajectory (default: 3000)")
    parser.add_argument("--time_step", type=int, default=40, help="Time step in atomic units (au) used during data generation (can be found in mdlog files for example) (default: 40)")
    return vars(parser.parse_args())


def set_path_and_remove_old_gradients(data_path: str, geo_dir: str, name: str) -> str:
    """
    Set the output path for the gradients and remove any old files if they exist.
    Args:
        data_path (str): Path to the directory containing all the data, i.e. all the GEO directories.
        geo_dir (str): Name of directory for which the gradients are being processed.
        name (str): Name of the output file.
    Returns:
        str: The output path for the gradients file.
    """
    output_path = os.path.join(data_path, geo_dir, "test", name)
    if os.path.exists(output_path):
        logger.info(f"Removing old file {output_path}")
        os.remove(output_path)
    return output_path

def extract_state_gradients(output_path: str, first_gradient_path: str, second_gradient_path: str, last_exited_cycle: int, 
                            total_cycles: int, time_step: float, command_path: str, state_label: str):
    """
    Extracts state gradients and writes to output file with a header.

    Args:
        output_path (str): Path to the output file.
        first_gradient_path (str): Path for cycles 1 to last_exited_cycle.
        second_gradient_path (str): Path for cycles last_exited_cycle+1 to total_cycles.
        last_exited_cycle (int): Last exited cycle index.
        total_cycles (int): Total number of cycles.
        time_step (float): Time step used in simulation (can be read from an mdlog file).
        command_path (str): Path to the gradient extraction bash script.
        state_label (str): Label for the state (e.g. "S0", "S1").
    """
    # Write header
    with open(output_path, "w") as f:
        f.write(f"# Extracted {state_label} gradients from {first_gradient_path} (cycles 1-{last_exited_cycle})\n")
        f.write(f"# and {second_gradient_path} (cycles {last_exited_cycle+1}-{total_cycles})\n")
        f.write("# All properties are in atomic units\n")

    # Append extracted gradients
    os.system(f"bash {command_path} {first_gradient_path} 1 {last_exited_cycle} {time_step} >> {output_path}")
    os.system(f"bash {command_path} {second_gradient_path} {last_exited_cycle+1} {total_cycles} {time_step} >> {output_path}")


def main(target_dir: str, computed_cycles: int, total_cycles: int, time_step: int):
    """
    Main function to extract s0 and s1 gradients from various files and save them to a text file.
    Args:
        target_dir (str): Directory where the log files are located.
    """
    # setup
    data_path = os.path.join(set_data_prefix(), target_dir)
    command_path = os.path.expanduser(f'~/whk/code/exited_md/preprocessing/extract_gradients.sh')
    logger.debug(f"data_path: {data_path}")
    
    # get all valid trajectories and the number of their last exited cycles
    last_exited_cycles = prepare_last_exited_cycles(data_path, computed_cycles)

    # exited cycle and then from ex_gradient file the rest
    for geo_dir, last_exited_cycle in tqdm(last_exited_cycles.items(), desc="Extracting gradients"):
        logger.info(f"Processing {geo_dir} with last exited cycle {last_exited_cycle}")
        s0_output_path = set_path_and_remove_old_file(data_path, geo_dir, "s0_gradients.txt")
        s1_output_path = set_path_and_remove_old_file(data_path, geo_dir, "s1_gradients.txt")

        # see (*) for explanation of the paths
        active_gradient_path = os.path.join(data_path, geo_dir, "test", "gradient")
        s0_gradient_path = os.path.join(data_path, "extra_ground_state_calculations", geo_dir, "ground_state_gradients.txt")
        s1_gradient_path = os.path.join(data_path, geo_dir, "test", "gradient_ex")
        if not os.path.exists(active_gradient_path) or not os.path.exists(s0_gradient_path) or not os.path.exists(s1_gradient_path):
            raise FileNotFoundError(f"File {active_gradient_path} or {s0_gradient_path} or {s1_gradient_path} does not exist. Skipping {geo_dir}.")

        
        # Extract S0 and S1 gradients
        extract_state_gradients(
            output_path=s0_output_path,
            first_gradient_path=s0_gradient_path,
            second_gradient_path=active_gradient_path,
            last_exited_cycle=last_exited_cycle,
            total_cycles=total_cycles,
            time_step=time_step,
            command_path=command_path,
            state_label="S0"
        )
        extract_state_gradients(
            output_path=s1_output_path,
            first_gradient_path=active_gradient_path,
            second_gradient_path=s1_gradient_path,
            last_exited_cycle=last_exited_cycle,
            total_cycles=total_cycles,
            time_step=time_step,
            command_path=command_path,
            state_label="S1"
        )
        logger.info(f"Extracted gradients for {geo_dir} with last exited cycle {last_exited_cycle} into {s0_output_path} and {s1_output_path}")
        


if __name__ == "__main__":
    args = parse_args()
    main(**args)
    
        